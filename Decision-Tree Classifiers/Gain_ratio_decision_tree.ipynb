{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    g=[0 for _ in range(2)]\n",
    "    for i in range(len(y)):\n",
    "        if(y[i] == 0):\n",
    "             g[0] += 1\n",
    "        else:\n",
    "            g[1] += 1\n",
    "    ps = np.divide(g,len(y))\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=2, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self.grow(X, y)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        \n",
    "        predicted_label=[self.traverse(x.iloc[i],self.root) for i in range(x.shape[0])]\n",
    "        return predicted_label\n",
    "\n",
    "    def grow(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # stopping criteria\n",
    "        if (depth >= self.max_depth\n",
    "                or n_labels == 1\n",
    "                or n_samples < self.min_samples_split):\n",
    "            leaf_value = self.find_label(y)\n",
    "            #print('leaf made')\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
    "\n",
    "        # greedily select the best split according to gini\n",
    "        best_feat = self.best_split(X, y, feat_idxs)\n",
    "        \n",
    "        # grow the children that result from the split\n",
    "        left_idxs, right_idxs,best_thresh = self._split(X.iloc[:,best_feat])\n",
    "        left = self.grow(X.iloc[left_idxs, :], y.iloc[left_idxs], depth+1)\n",
    "        right = self.grow(X.iloc[right_idxs, :], y.iloc[right_idxs], depth+1)\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "\n",
    "    def best_split(self, X, y, feat_idxs):\n",
    "        best_ig = 0\n",
    "        split_idx= None\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X.iloc[:, feat_idx]\n",
    "            gain =  self.gainratio(X_column,y.to_numpy())\n",
    "            \n",
    "            #print(gini[0])\n",
    "            if  gain > best_ig:\n",
    "                best_ig = gain\n",
    "                split_idx = feat_idx\n",
    "        #print('best ig found at ',split_idx)\n",
    "        return split_idx \n",
    "    \n",
    "    def infogain(self,X_column,y):\n",
    "        # parent loss\n",
    "        parent_entropy = entropy(y)\n",
    "\n",
    "        # generate split\n",
    "        left_idxs, right_idxs,threshold = self._split(X_column)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # compute the weighted avg. of the loss for the children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = entropy(y[left_idxs]), entropy(y[right_idxs])\n",
    "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "\n",
    "        # information gain is difference in loss before vs. after split\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "\n",
    "    def _split(self,data):\n",
    "        #mean= np.mean(data.iloc[:,node].to_numpy())\n",
    "        mean= data.mean(axis=0)\n",
    "        left=[]\n",
    "        right=[]\n",
    "        for row in range(data.shape[0]):\n",
    "            if data.iloc[row]<mean:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        #print('split made')\n",
    "        return left,right,mean\n",
    "    \n",
    "    \n",
    "    def traverse(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        #print(x[node.feature])\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self.traverse(x, node.left)\n",
    "        return self.traverse(x, node.right)\n",
    "\n",
    "    def find_label(self, y):\n",
    "        y = list(y)\n",
    "        s0=0\n",
    "        s1=0\n",
    "        for i in range(len(y)):\n",
    "            if y[i]>0:\n",
    "                s1+=1\n",
    "            else:\n",
    "                s0+=1\n",
    "        if s0> s1:\n",
    "            return 0\n",
    "        else :\n",
    "            return 1\n",
    "    def print_tree(self,tree=None,indent=\" \"):\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "        if tree.value!=None:\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"x \"+ df.columns[tree.feature],\"<=\",tree.threshold)\n",
    "            print(\"%sleft:\" % (indent),end=\"\")\n",
    "            self.print_tree(tree.left,indent+indent)\n",
    "            print(\"%sright:\" % (indent),end=\"\")\n",
    "            self.print_tree(tree.right,indent+indent)\n",
    "    \n",
    "    def gainratio(self,df, label):\n",
    "    \n",
    "        gain_split = self.infogain(df, label)\n",
    "        l = len(df)\n",
    "        #w = len(df[0])\n",
    "        mean = df.mean(axis=0)\n",
    "\n",
    "        #gai = []\n",
    "        split = []\n",
    "        left_idxs, right_idxs,threshold = self._split(df)\n",
    "        observed_t = [[0 for _ in range(2)] for _ in range(2)]\n",
    "        #expected_t = [[0 for _ in range(2)] for _ in range(2)]\n",
    "        sum_t = [0 ,0]\n",
    "        \n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        for i in left_idxs:\n",
    "            if(label[i] == 0):\n",
    "                    observed_t[0][0] += 1\n",
    "            else:\n",
    "                    observed_t[0][1] += 1\n",
    "        \n",
    "        for i in right_idxs:\n",
    "                if(label[i] == 0):\n",
    "                    observed_t[1][0] += 1\n",
    "                else:\n",
    "                    observed_t[1][1] += 1\n",
    "                    \n",
    "        sum_t = list(np.sum(observed_t, axis = 1))\n",
    "         \n",
    "        split_info = - (sum_t[0]/sum(sum_t)) * math.log(sum_t[0]/sum(sum_t), 2) - (sum_t[1]/sum(sum_t)) * math.log(sum_t[1]/sum(sum_t), 2)\n",
    "        \n",
    "        split.append(split_info)\n",
    "        \n",
    "        gain = np.divide(gain_split, split)\n",
    "    \n",
    "        return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('31.csv',header=None)\n",
    "for row in range(df.shape[0]):\n",
    "    if df.iloc[row,-1]>0:\n",
    "        df.iloc[row,-1]=1\n",
    "    else:\n",
    "        df.iloc[row,-1]=0\n",
    "string = 'feature'\n",
    "df.columns = [string+str(i) for i in range(df.shape[1])]\n",
    "#print(df.columns)    \n",
    "max_depth =int(math.log2(df.shape[1]))\n",
    "#max_depth =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.iloc[:,:-1]\n",
    "Y= df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x feature7 <= 9.177275891406914\n",
      " left:x feature14 <= 0.5447193478003083\n",
      "  left:x feature14 <= 0.27561422175950034\n",
      "    left:x feature16 <= 1.1859872611464968\n",
      "        left:0\n",
      "        right:0\n",
      "    right:x feature3 <= 8.753521126760564\n",
      "        left:0\n",
      "        right:0\n",
      "  right:x feature12 <= 0.06512742321934219\n",
      "    left:x feature7 <= 3.5167785234899327\n",
      "        left:0\n",
      "        right:0\n",
      "    right:0\n",
      " right:x feature3 <= 22.612099644128115\n",
      "  left:x feature5 <= 30.686634460547506\n",
      "    left:x feature3 <= 14.858734580183048\n",
      "        left:0\n",
      "        right:0\n",
      "    right:x feature1 <= 1.724662162162162\n",
      "        left:0\n",
      "        right:0\n",
      "  right:x feature3 <= 39.29259525521208\n",
      "    left:x feature1 <= 1.9819458375125376\n",
      "        left:0\n",
      "        right:0\n",
      "    right:x feature4 <= 140.748730964467\n",
      "        left:0\n",
      "        right:1\n"
     ]
    }
   ],
   "source": [
    "classifier= DecisionTree(2,max_depth)\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.print_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8556477805846265\n"
     ]
    }
   ],
   "source": [
    "Y_pred= classifier.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8552869000360881\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy',splitter='best',max_depth=4,random_state=1)\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_7 <= 21.50\n",
      "|   |--- feature_17 <= 11.56\n",
      "|   |   |--- feature_14 <= 0.27\n",
      "|   |   |   |--- feature_6 <= 12.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_6 >  12.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_14 >  0.27\n",
      "|   |   |   |--- feature_7 <= 2.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_7 >  2.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |--- feature_17 >  11.56\n",
      "|   |   |--- feature_14 <= 0.11\n",
      "|   |   |   |--- feature_17 <= 18.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_17 >  18.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_14 >  0.11\n",
      "|   |   |   |--- feature_7 <= 7.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_7 >  7.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|--- feature_7 >  21.50\n",
      "|   |--- feature_4 <= 130.50\n",
      "|   |   |--- feature_18 <= 2.50\n",
      "|   |   |   |--- feature_17 <= 144.17\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_17 >  144.17\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_18 >  2.50\n",
      "|   |   |   |--- feature_13 <= 0.86\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_13 >  0.86\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |--- feature_4 >  130.50\n",
      "|   |   |--- feature_4 <= 338.50\n",
      "|   |   |   |--- feature_18 <= 12.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_18 >  12.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_4 >  338.50\n",
      "|   |   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_representation = tree.export_text(clf)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
